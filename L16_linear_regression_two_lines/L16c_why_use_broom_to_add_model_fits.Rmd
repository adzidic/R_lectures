---
title: "Why you should use broom to visualise models on ggplots"
date: "`r format(Sys.time(), '%d %B %Y')`"

output: html_notebook
---    

This script uses simulated data to illustrate the dangers of taking shortcuts with ggplot when representing fitted models using an ANCOVA setup. 

## Setup

```{r setup}
library(tidyverse)
library(magrittr)
library(broom)
library(patchwork)
```


## Generate the data

Make two groups of data following a linear regression relationship. One of the groups is has fewer observations and larger variance to highlight the effect.

```{r}

set.seed(2)

# generate 10 data points on a line with relatively small error
dd1 <- data.frame(X = 1:10, Y = 1:10 * 2 + rnorm(10, 0, 1), G = "A")

# generate 5 data points on a line with relatively large error
dd2 <- data.frame(X = 1:5, Y = 1:5 * 4  + rnorm(5, 0, 3),  G = "B")

# combine dataframes
dd <- bind_rows(dd1, dd2)

```

## Plot the data

```{r}

g1 <- ggplot(data = dd, mapping = aes(x = X, y = Y, color = G)) + 
  geom_point() + 
  scale_color_viridis_d(end = 0.9) + 
  theme_classic()

print(g1)

```

## Fit a linear model

Fit a model with two intercepts and two slopes. 

```{r}

# fit a model that effectivley fits non-parallel lines
mod1 <- glm(Y ~ X + G + X:G, data = dd)

```

## Add lines using stat_smoot()

We can very easily add lines to our plot above using `geom_smooth()` which is great. __*But*__ this is __*not*__ the same thing as fitted by our model. 

```{r}

# add the linear smoothed lines to g1
g2 <- g1 + geom_smooth(method = "lm")

print(g2)
```

The important thing to note is that the two lines have been been generated by effectively splitting the dataset in two based on the grouping variable `G`. This means that we have estimated one slope, one intercept and one error term for each of the two lines. This means that the corresponding confidence intervals for the lines are constructed independently using their respective error terms. This is in contrast to what we modelled in the linear model above where we allowed two slopes, two intercepts but one common error term. 

## Fitting the actual model

We can use the broom package to generate estimated values based on the linear model and use that information to construct the estimated lines and their confidence intervals. We use the `augment()` function from the `broom` package to generate a new data.frame (also a tibble) object that contains the original data augmented to include the fitted values according to the linear model and their errors. 

```{r}

mod1_fitted <- mod1 %>% augment(se_fit = TRUE)

g_model1 <- ggplot(data = mod1_fitted, 
                   mapping = aes(x = X, y = Y, 
                                 color = G)) + 
  geom_ribbon(aes(ymin = .fitted-1.96*.se.fit, 
                  ymax = .fitted+1.96*.se.fit), 
              alpha=0.2, linetype = 0) +
  geom_point() + 
  geom_line(aes(x = X, y = .fitted)) + 
  scale_color_viridis_d(end = 0.9) + 
  theme_classic()

print(g_model1)

```

## Things are not alike

Putting them side-by-side, we can clearly see the difference in the fitted lines. While their means (the lines) are the same in both, the uncertainties are very different owing to shared error term in the actual linear model we fitted to the data. 

Just having the confidence intervals being different is not the end of the world, but you must be very careful in more complex models. If you have fitted random effects in a linear model, it will be almost certain that the actual slopes and/or intercepts will be different and you could end up with a very different picture being painted between the fitted model and the visualisation appraoch you've taken.

```{r}

(g2 + ggtitle("geom_smooth") + ylim(0, 30) | g_model1 + ggtitle("broom") + ylim(0, 30))

```




## Conclusion 

In conclusion, I am strongly of the view that you should strive to illustrate your actual fitted model alongside your data when visualising the results. 




